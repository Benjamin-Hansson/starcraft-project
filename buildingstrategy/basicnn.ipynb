{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pklVAdTJ6J-B"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_L-5xPvzna4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BatchEnv(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def init(self, path, root, race, enemy_race, step_mul=8, n_replays=4, n_steps=5, epochs=10, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        with open(path) as f:\n",
    "            replays = json.load(f)\n",
    "\n",
    "        self.replays = self.__generate_replay_list__(replays, root, race)\n",
    "\n",
    "        self.race = race\n",
    "        self.enemy_race = enemy_race\n",
    "\n",
    "        self.step_mul = step_mul\n",
    "        self.n_replays = n_replays\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.epoch = -1\n",
    "        self.steps = 0\n",
    "\n",
    "        self.replay_idx = -1\n",
    "        self.replay_list = [None for _ in range(self.n_replays)]\n",
    "        \n",
    "        ## Display Progress Bar\n",
    "        \"\"\"\n",
    "        self.epoch_pbar = tqdm(total=self.epochs, desc='Epoch')\n",
    "        self.replay_pbar = None\n",
    "        \"\"\"\n",
    "\n",
    "        self.__post_init__()\n",
    "\n",
    "    def __generate_replay_list__(self, replays, race):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __init_epoch__(self):\n",
    "        self.epoch += 1\n",
    "        \"\"\"\n",
    "        if self.epoch > 0:\n",
    "            self.epoch_pbar.update(1)\n",
    "        \"\"\"\n",
    "        if self.epoch == self.epochs:\n",
    "            return False\n",
    "\n",
    "        np.random.shuffle(self.replays)\n",
    "        ## Display Progress Bar\n",
    "        \"\"\"\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        self.replay_pbar = tqdm(total=len(self.replays), desc='  Replays')\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def __reset__(self):\n",
    "        self.replay_idx += 1\n",
    "        if self.replay_idx % len(self.replays) == 0:\n",
    "            has_more = self.__init_epoch__()\n",
    "            if not has_more:\n",
    "                return None\n",
    "\n",
    "        path = self.replays[self.replay_idx%len(self.replays)]\n",
    "\n",
    "        return self.__load_replay__(path)\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, **kwargs):\n",
    "        require_init = [False for _ in range(self.n_replays)]\n",
    "        for i in range(self.n_replays):\n",
    "            if self.replay_list[i] is None or self.replay_list[i]['done']:\n",
    "                if self.replay_list[i] is not None:\n",
    "                    keys = set(self.replay_list[i].keys())\n",
    "                    for k in keys:\n",
    "                        del self.replay_list[i][k]\n",
    "                self.replay_list[i] = self.__reset__()\n",
    "                require_init[i] = True\n",
    "            if self.replay_list[i] is None:\n",
    "                return None\n",
    "\n",
    "        result = []\n",
    "        for step in range(self.n_steps):\n",
    "            result_per_step = []\n",
    "            for i in range(self.n_replays):\n",
    "                replay_dict = self.replay_list[i]\n",
    "\n",
    "                features = self.__one_step__(replay_dict, replay_dict['done'])\n",
    "\n",
    "                result_per_step.append(features)\n",
    "\n",
    "            result.append(result_per_step)\n",
    "\n",
    "        return self.__post_process__(result, **kwargs), require_init\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __post_process__(self, result, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step_count(self):\n",
    "        return self.steps\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        if self.epoch_pbar is not None:\n",
    "            self.epoch_pbar.close()\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        \"\"\"\n",
    "            \n",
    "class BatchGlobalFeatureEnv(BatchEnv):\n",
    "    n_features_dic = {'Terran':  {'Terran': 738,  'Protoss': 648,  'Zerg': 1116},\n",
    "                      'Protoss': {'Terran': 638,  'Protoss': 548,  'Zerg': 1016},\n",
    "                      'Zerg':    {'Terran': 1106, 'Protoss': 1016, 'Zerg': 1484}}\n",
    "    n_actions_dic = {'Terran': 75, 'Protoss': 61, 'Zerg': 74}\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.n_features = self.n_features_dic[self.race][self.enemy_race]\n",
    "        self.n_actions = self.n_actions_dic[self.race]\n",
    "\n",
    "    def __generate_replay_list__(self, replays, root, race):\n",
    "        result = []\n",
    "        for path_dict in replays:\n",
    "            for player_path in path_dict[race]:\n",
    "                result.append(os.path.join(root, player_path['global_path']))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        replay_dict = {}\n",
    "        replay_dict['ptr'] = 0\n",
    "        replay_dict['done'] = False\n",
    "        replay_dict['states'] = np.asarray(sparse.load_npz(path).todense())\n",
    "\n",
    "        return replay_dict\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        states = replay_dict['states']\n",
    "        feature_shape = states.shape[1:]\n",
    "        if done:\n",
    "            return np.zeros(feature_shape)\n",
    "\n",
    "        self.steps += 1\n",
    "        state = states[replay_dict['ptr']]\n",
    "        replay_dict['ptr'] += 1\n",
    "        if replay_dict['ptr'] == states.shape[0]:\n",
    "            #self.replay_pbar.update(1)\n",
    "            replay_dict['done'] = True\n",
    "    \n",
    "        return state\n",
    "\n",
    "    def __post_process__(self, result, reward=True, action=False, score=False):\n",
    "        result = np.asarray(result)\n",
    "\n",
    "        result_return = [result[:, :, 15:]]\n",
    "        if reward:\n",
    "            result_return.append(result[:, :, 0:1])\n",
    "        if action:\n",
    "            result_return.append(result[:, :, 1:2])\n",
    "        if score:\n",
    "            result_return.append(result[:, :, 2:15])\n",
    "\n",
    "        return result_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5101,
     "status": "ok",
     "timestamp": 1573819158300,
     "user": {
      "displayName": "Dylan Mäenpää",
      "photoUrl": "https://lh5.googleusercontent.com/-G0n0W6eJ4i8/AAAAAAAAAAI/AAAAAAAAAC8/xxtHPKSBYvs/s64/photo.jpg",
      "userId": "01206227338381553752"
     },
     "user_tz": -60
    },
    "id": "KWg6kn_i6J-O",
    "outputId": "4f0eceda-7d3e-4049-b3b8-2532df0f3808"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Todo, change output size\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 75)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all features except for\n",
    "# minerals, vespene, food_cap, food_used, food_army, food_workers\n",
    "\n",
    "REMOVE = [74, 1, 11, 0, 16, 17, 18, 19, 22, 23, 26, 27, 28, 33, 30, 31, 35, 38, 34]\n",
    "def transform(states):\n",
    "    mask = np.ones([1, 256, 738], dtype=bool)\n",
    "    mask[:, :, 7:] = False\n",
    "    mask[:, :, 0] = False\n",
    "    states=states[mask]\n",
    "    return states\n",
    "\n",
    "# Removes not wanted actions from above\n",
    "def transform2(states, actions, n_replays):\n",
    "    mask = np.ones(n_replays, dtype=bool)\n",
    "    for i, action in enumerate(actions.squeeze()):\n",
    "        if action in REMOVE:\n",
    "            mask[i] = False\n",
    "    actions = actions.squeeze()[mask]\n",
    "    states = transform(states)\n",
    "    states = np.reshape(states, (256, -1))\n",
    "    states = states[mask]\n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7QZ9AYWvrvI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loss: 0.18283398008346557/6854 epoch: 1\n",
      "loss: 0.16752377438545227/6854 epoch: 1\n",
      "loss: 0.16715827047824868/6854 epoch: 1\n",
      "loss: 0.170545044898986862/6854 epoch: 1\n",
      "loss: 0.167154995918273931/6854 epoch: 1\n",
      "loss: 0.163864910721778862/6854 epoch: 1\n",
      "loss: 0.161039312124252320/6854 epoch: 1\n",
      "loss: 0.158598248004913325/6854 epoch: 1\n",
      "loss: 0.157986801981925978/6854 epoch: 1\n",
      "loss: 0.156798459589481359/6854 epoch: 1\n",
      "loss: 0.157180414080619867/6854 epoch: 1\n",
      "loss: 0.155282535910606435/6854 epoch: 1\n",
      "loss: 0.158897431015968328/6854 epoch: 1\n",
      "loss: 0.156733305156230932/6854 epoch: 1\n",
      "loss: 0.1576401292085647701/6854 epoch: 1\n",
      "loss: 0.1580444236993789657/6854 epoch: 1\n",
      "loss: 0.1569452421665191726/6854 epoch: 1\n",
      "loss: 0.1619245779514312874/6854 epoch: 1\n",
      "loss: 0.1613486578464508218/6854 epoch: 1\n",
      "loss: 0.1583392103910446286/6854 epoch: 1\n",
      "loss: 0.1579490339756012339/6854 epoch: 1\n",
      "loss: 0.1583137593269348397/6854 epoch: 1\n",
      "loss: 0.1584616203308105443/6854 epoch: 1\n",
      "loss: 0.1574515274763107298/6854 epoch: 1\n",
      "loss: 0.1559936083555221560/6854 epoch: 1\n",
      "loss: 0.1565194072723388726/6854 epoch: 1\n",
      "loss: 0.1572366966009141681/6854 epoch: 1\n",
      "loss: 0.1566839140653610333/6854 epoch: 1\n",
      "loss: 0.1597765784263611783/6854 epoch: 1\n",
      "loss: 0.1584323376417161844/6854 epoch: 1\n",
      "loss: 0.1601427079439163395/6854 epoch: 1\n",
      "loss: 0.16041250658035278937/6854 epoch: 1\n",
      "loss: 0.15876887261867523992/6854 epoch: 1\n",
      "loss: 0.15709892201423645053/6854 epoch: 1\n",
      "loss: 0.15688277149200439108/6854 epoch: 1\n",
      "loss: 0.15396327656507492170/6854 epoch: 1\n",
      "loss: 0.15664024597406387227/6854 epoch: 1\n",
      "loss: 0.15609657669067384286/6854 epoch: 1\n",
      "loss: 0.15824879252910615332/6854 epoch: 1\n",
      "loss: 0.15560099065303803384/6854 epoch: 1\n",
      "loss: 0.15498696470260622440/6854 epoch: 1\n",
      "loss: 0.15657415175437928504/6854 epoch: 1\n",
      "loss: 0.15591014611721038557/6854 epoch: 1\n",
      "loss: 0.15721494948863984614/6854 epoch: 1\n",
      "loss: 0.16050370508432388673/6854 epoch: 1\n",
      "loss: 0.15598389184474945728/6854 epoch: 1\n",
      "loss: 0.15841036927700042784/6854 epoch: 1\n",
      "loss: 0.15514647996425632852/6854 epoch: 1\n",
      "loss: 0.15714026165008546900/6854 epoch: 1\n",
      "loss: 0.15399896073341372960/6854 epoch: 1\n",
      "loss: 0.15345755350589751025/6854 epoch: 1\n",
      "loss: 0.15848394441604613072/6854 epoch: 1\n",
      "loss: 0.15813709580898286123/6854 epoch: 1\n",
      "loss: 0.15873585057258605173/6854 epoch: 1\n",
      "loss: 0.15398433578014373240/6854 epoch: 1\n",
      "loss: 0.15441850709915161295/6854 epoch: 1\n",
      "loss: 0.15565000319480896352/6854 epoch: 1\n",
      "loss: 0.15735572361946107404/6854 epoch: 1\n",
      "loss: 0.15576240420341492459/6854 epoch: 1\n",
      "loss: 0.16083307540416716509/6854 epoch: 1\n",
      "loss: 0.15749691259860993567/6854 epoch: 1\n",
      "loss: 0.15348808342218398635/6854 epoch: 1\n",
      "loss: 0.15641397774219512691/6854 epoch: 1\n",
      "loss: 0.15537082362174987750/6854 epoch: 1\n",
      "loss: 0.15550454640388493810/6854 epoch: 1\n",
      "loss: 0.15758241403102874857/6854 epoch: 1\n",
      "loss: 0.15680968749523164920/6854 epoch: 1\n",
      "loss: 0.15874787449836733972/6854 epoch: 1\n",
      "loss: 0.15736869597434996023/6854 epoch: 1\n",
      "loss: 0.15354077017307283083/6854 epoch: 1\n",
      "loss: 0.15381508743762974138/6854 epoch: 1\n",
      "loss: 0.15470923149585725210/6854 epoch: 1\n",
      "loss: 0.15436762630939482271/6854 epoch: 1\n",
      "loss: 0.15802314651012424321/6854 epoch: 1\n",
      "loss: 0.15741931343078613375/6854 epoch: 1\n",
      "loss: 0.15069235962629318450/6854 epoch: 1\n",
      "loss: 0.15430584490299226494/6854 epoch: 1\n",
      "loss: 0.15269261765480044551/6854 epoch: 1\n",
      "loss: 0.15578703796863555605/6854 epoch: 1\n",
      "loss: 0.15694186353683473657/6854 epoch: 1\n",
      "loss: 0.15516088581085205712/6854 epoch: 1\n",
      "loss: 0.15256553381681442777/6854 epoch: 1\n",
      "loss: 0.15513606089353563823/6854 epoch: 1\n",
      "loss: 0.15475280964374544877/6854 epoch: 1\n",
      "loss: 0.15356177449226384938/6854 epoch: 1\n",
      "loss: 0.15382899475097656000/6854 epoch: 1\n",
      "loss: 0.15457060146331786059/6854 epoch: 1\n",
      "loss: 0.15921528375148772110/6854 epoch: 1\n",
      "loss: 0.15886467266082763166/6854 epoch: 1\n",
      "loss: 0.15762130165100097218/6854 epoch: 1\n",
      "loss: 0.15514441716670995284/6854 epoch: 1\n",
      "loss: 0.15609809559583665338/6854 epoch: 1\n",
      "loss: 0.15576091855764395389/6854 epoch: 1\n",
      "loss: 0.15498719143867493436/6854 epoch: 1\n",
      "loss: 0.15163564354181295499/6854 epoch: 1\n",
      "loss: 0.14745077335834503572/6854 epoch: 1\n",
      "loss: 0.15345924896001817609/6854 epoch: 1\n",
      "loss: 0.15222247946262365671/6854 epoch: 1\n",
      "loss: 0.14742462420463562729/6854 epoch: 1\n",
      "loss: 0.15408101761341095770/6854 epoch: 1\n",
      "loss: 0.15427644121646885827/6854 epoch: 1\n",
      "loss: 0.15338273417949677867/6854 epoch: 1\n",
      "loss: 0.14881172418594365938/6854 epoch: 1\n",
      "loss: 0.15123647713661195991/6854 epoch: 1\n",
      "loss: 0.15308612656593323044/6854 epoch: 1\n",
      "loss: 0.15359816008806236108/6854 epoch: 1\n",
      "loss: 0.15168379139900207159/6854 epoch: 1\n",
      "loss: 0.15342933189868926203/6854 epoch: 1\n",
      "loss: 0.14945473301410675275/6854 epoch: 1\n",
      "loss: 0.15183681666851043323/6854 epoch: 1\n",
      "loss: 0.15030953276157386374/6854 epoch: 1\n",
      "loss: 0.14879912668466576438/6854 epoch: 1\n",
      "loss: 0.14989078819751746505/6854 epoch: 1\n",
      "loss: 0.15162638902664186553/6854 epoch: 1\n",
      "loss: 0.15059737914800644612/6854 epoch: 1\n",
      "loss: 0.15071977156400682667/6854 epoch: 1\n",
      "loss: 0.15241510450839996718/6854 epoch: 1\n",
      "loss: 0.15240093463659288768/6854 epoch: 1\n",
      "loss: 0.15390596818923956818/6854 epoch: 1\n",
      "steps: 3825664, replay: 6851/6854 epoch: 1\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-023936c9eecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"train_val_test/Terran_vs_Terran/val.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menemy_race\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_replays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_replays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import visdom\n",
    "import sys\n",
    "\n",
    "# Todo:\n",
    "# Ta bort cancel outputs också?\n",
    "# Ta bort onödiga outputs\n",
    "# Ta bort do nothing output\n",
    "# Om tid: träna på mer epoker\n",
    "# Om tid: mer input\n",
    "\n",
    "def train(model, env):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    env_return = env.step(reward=True, action=True)\n",
    "    print(env.epochs)\n",
    "    \n",
    "    if env_return is not None:\n",
    "        (states, reward, actions_gt), require_init = env_return\n",
    "   \n",
    "    # Remove doing nothing\n",
    "    states = torch.from_numpy(states).float().view(env.n_replays, -1)\n",
    "    actions_gt = torch.from_numpy(actions_gt).long().squeeze()\n",
    "    \n",
    "    states, actions_gt = transform2(states, actions_gt, n_replays)\n",
    "    running_loss = 0\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        #print(\"steps: {} \\n epochs: {} \", end='\\r')#.format(env.steps, env.epochs))\n",
    "        print(\"steps: {}, replay: {}/{} epoch: {}\".format(env.step_count(), env.replay_idx, len(env.replays), env.epoch+1), end=\"\\r\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # since we are not using steps we need o reshape result\n",
    "        actions = model(states)\n",
    "        \n",
    "        loss = 0\n",
    "        loss += F.cross_entropy(actions, actions_gt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #print(model.fc1.weight)\n",
    "        optimizer.step()\n",
    "        #print(model.fc1.weight)\n",
    "        \n",
    "        \n",
    "        env_return = env.step(reward=False, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_states, raw_actions_gt), require_init = env_return\n",
    "            states = torch.from_numpy(raw_states).float().view(env.n_replays, -1)\n",
    "            actions_gt = torch.from_numpy(raw_actions_gt).long().squeeze()\n",
    "            states, actions_gt = transform2(states, actions_gt, n_replays)\n",
    "        \n",
    "        #env.step_count() > save or\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if env.steps % 2000 == 0:\n",
    "            print(\"loss: {}\".format(running_loss/2000))\n",
    "            running_loss = 0\n",
    "        if env.epoch == env.epochs:\n",
    "            torch.save(model.state_dict(), 'model_iter_{}.pth'.format(env.step_count()))\n",
    "            return\n",
    "        if env_return is None:\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "replay_path = ''\n",
    "dataset_path = ''\n",
    "race = 'Terran'\n",
    "enemy_race = 'Terran'\n",
    "steps = 20 # ?\n",
    "n_replays = 256\n",
    "epochs = 1\n",
    "model = Net()\n",
    "\n",
    "path = 'train_val_test/Terran_vs_Terran/train.json'\n",
    "phrase = 'train'\n",
    "\n",
    "env = BatchGlobalFeatureEnv()\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=1)\n",
    "\n",
    "train(model, env)\n",
    "path = \"train_val_test/Terran_vs_Terran/val.json\"\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=1)\n",
    "accuracy, actions = test(model, env)\n",
    "print()\n",
    "print(accuracy)\n",
    "\n",
    "#initial features\n",
    "\"\"\"\n",
    "tensor([0.0001, 0.0008, 0.0000, 0.0750, 0.0600, 0.0000, 0.0600, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raGDqFNX47Za"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test(model, env):\n",
    "    print(\"Testing\")\n",
    "    ######################### SAVE RESULT ############################\n",
    "    total_data_points = 0\n",
    "    correct = 0\n",
    "    correct_dumb = 0\n",
    "    correct_three = 0\n",
    "    saved_actions = defaultdict(int)\n",
    "    ######################### TEST ###################################\n",
    "    env_return = env.step(reward=False, action=True)\n",
    "    if env_return is not  None:\n",
    "        (states, actions_gt), require_init = env_return\n",
    "        states = transform(states)\n",
    "        states = torch.from_numpy(states).float().view(env.n_replays, -1)\n",
    "        actions_gt = torch.from_numpy(actions_gt).long().squeeze()\n",
    "    not_bad = 0\n",
    "    while True:\n",
    "        print(\"steps: {}, replay: {}/{} epoch: {}\".format(env.step_count(), env.replay_idx, len(env.replays), env.epoch+1), end=\"\\r\")\n",
    "        actions = model(states).view(env.n_replays, -1)\n",
    "        actions.detach()\n",
    "        #rint(np.argpartition(actions[0].detach().numpy(), -3)[-3:])\n",
    "        #beak\n",
    "        ########################### NEXT BATCH #############################################\n",
    "        actions_np = np.squeeze(np.vstack([np.argpartition(action.detach().numpy(), -3)[-3:] for action in actions]))\n",
    "        #actions_np = np.squeeze(np.vstack([np.argmax(action.data.cpu().numpy(), axis=0) for action in actions]))\n",
    "        for three_actions in actions_np:\n",
    "            for action in three_actions:\n",
    "                saved_actions[action] +=1\n",
    "        actions_gt_np = np.squeeze(actions_gt.cpu().numpy())\n",
    "        for i, action in enumerate(actions_gt_np):\n",
    "            if action not in REMOVE:\n",
    "                if action == actions_np[i][2]:\n",
    "                    correct += 1\n",
    "                if action in actions_np[i]:\n",
    "                    correct_three += 1\n",
    "                if action == 62:\n",
    "                    correct_dumb += 1\n",
    "                total_data_points += 1\n",
    "                \n",
    "        if env.epoch == env.epochs:\n",
    "            break\n",
    "        \n",
    "        env_return = env.step(reward=False, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_states, raw_actions), require_init = env_return\n",
    "            raw_states = transform(raw_states)\n",
    "            states = states.copy_(torch.from_numpy(raw_states).float().view(env.n_replays, -1))\n",
    "            actions_gt = actions_gt.copy_(torch.from_numpy(raw_actions).long().squeeze())\n",
    "        else:\n",
    "            env.close()\n",
    "    \n",
    "\n",
    "    return correct / total_data_points, correct_dumb/total_data_points, correct_three/total_data_points, saved_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "steps: 474624, replay: 980/980 epoch: 2\r"
     ]
    }
   ],
   "source": [
    "replay_path = ''\n",
    "dataset_path = ''\n",
    "race = 'Terran'\n",
    "enemy_race = 'Terran'\n",
    "steps = 20 # ?\n",
    "n_replays = 256\n",
    "epochs = 1\n",
    "model = Net()\n",
    "\n",
    "path = 'train_val_test/Terran_vs_Terran/train.json'\n",
    "phrase = 'train'\n",
    "\n",
    "model = Net()\n",
    "path = \"train_val_test/Terran_vs_Terran/val.json\"\n",
    "PATH = \"model_iter_3813888.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "env = BatchGlobalFeatureEnv()\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=1)\n",
    "accuracy, accuracy_dumb, accuracy_three, actions = test(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22598555343494023"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build_Refinery_screen\n"
     ]
    }
   ],
   "source": [
    "        import random\n",
    "        gas = 12\n",
    "        minerals = 50\n",
    "        supply = 15\n",
    "        max_supply = 20\n",
    "\n",
    "        #normalize\n",
    "        food_cap = max_supply / 200\n",
    "        input_minerals = minerals/ 62500\n",
    "        input_gas = gas / 62500\n",
    "        food_used = supply / 200\n",
    "        # TODO, fix this\n",
    "        food_army = (supply - supply/2) / 200\n",
    "        food_workers = (supply / 2) / 200\n",
    "        \"\"\"\n",
    "        print(\"gas: {}\".format(gas))\n",
    "        print(\"minerals: {}\".format(minerals))\n",
    "        print(\"supply: {}\".format(supply))\n",
    "        print(\"supply: {}\".format(max_supply))\n",
    "        \"\"\"\n",
    "        v = torch.Tensor([input_minerals, input_gas, food_cap, food_used, food_army, food_workers])\n",
    "        # Hardcoded input atm\n",
    "        predicted = model(v)\n",
    "        predicted = np.argpartition(predicted.detach().numpy(), -3)[-3:]\n",
    "        print(action_name[test[str(random.choice(predicted))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop_quick\n",
      "Build_SupplyDepot_screen\n",
      "Train_SCV_quick\n",
      "Build_Refinery_screen\n",
      "Build_Barracks_screen\n",
      "Build_CommandCenter_screen\n",
      "Build_Factory_screen\n",
      "Train_Marine_quick\n",
      "Train_Reaper_quick\n",
      "Build_Starport_screen\n",
      "Build_TechLab_quick\n",
      "Build_MissileTurret_screen\n",
      "Train_SiegeTank_quick\n",
      "Train_VikingFighter_quick\n",
      "Train_Battlecruiser_quick\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_id =  {'140': '1',\n",
    "               '168': '11',\n",
    "               '261': '0',\n",
    "               '300': '16',\n",
    "               '301': '17',\n",
    "               '304': '18',\n",
    "               '305': '19',\n",
    "               '309': '22',\n",
    "               '312': '23',\n",
    "               '317': '26',\n",
    "               '318': '27',\n",
    "               '319': '28',\n",
    "               '320': '33',\n",
    "               '321': '30',\n",
    "               '322': '31',\n",
    "               '326': '35',\n",
    "               '327': '38',\n",
    "               '352': '58',\n",
    "               '353': '55',\n",
    "               '354': '57',\n",
    "               '355': '56',\n",
    "               '361': '61',\n",
    "               '362': '63',\n",
    "               '363': '65',\n",
    "               '369': '67',\n",
    "               '370': '70',\n",
    "               '371': '69',\n",
    "               '375': '72',\n",
    "               '378': '73',\n",
    "               '39': '10',\n",
    "               '402': '2',\n",
    "               '403': '3',\n",
    "               '405': '4',\n",
    "               '406': '5',\n",
    "               '410': '6',\n",
    "               '414': '7',\n",
    "               '418': '8',\n",
    "               '419': '9',\n",
    "               '42': '13',\n",
    "               '423': '12',\n",
    "               '43': '14',\n",
    "               '44': '15',\n",
    "               '453': '34',\n",
    "               '459': '39',\n",
    "               '460': '40',\n",
    "               '464': '42',\n",
    "               '468': '44',\n",
    "               '469': '45',\n",
    "               '470': '46',\n",
    "               '475': '54',\n",
    "               '476': '49',\n",
    "               '477': '51',\n",
    "               '478': '52',\n",
    "               '487': '59',\n",
    "               '488': '60',\n",
    "               '490': '62',\n",
    "               '492': '64',\n",
    "               '496': '66',\n",
    "               '498': '68',\n",
    "               '50': '20',\n",
    "               '502': '71',\n",
    "               '53': '21',\n",
    "               '56': '24',\n",
    "               '58': '25',\n",
    "               '64': '29',\n",
    "               '66': '32',\n",
    "               '71': '36',\n",
    "               '72': '37',\n",
    "               '79': '41',\n",
    "               '83': '43',\n",
    "               '89': '47',\n",
    "               '91': '48',\n",
    "               '92': '50',\n",
    "               '93': '53'}\n",
    "action_name = { '140': 'Cancel_quick',\n",
    "                 '168': 'Cancel_Last_quick',\n",
    "                 '261': 'Halt_quick',\n",
    "                 '300': 'Morph_Hellbat_quick',\n",
    "                 '301': 'Morph_Hellion_quick',\n",
    "                 '304': 'Morph_LiberatorAAMode_quick',\n",
    "                 '305': 'Morph_LiberatorAGMode_screen',\n",
    "                 '309': 'Morph_OrbitalCommand_quick',\n",
    "                 '312': 'Morph_PlanetaryFortress_quick',\n",
    "                 '317': 'Morph_SiegeMode_quick',\n",
    "                 '318': 'Morph_SupplyDepot_Lower_quick',\n",
    "                 '319': 'Morph_SupplyDepot_Raise_quick',\n",
    "                 '320': 'Morph_ThorExplosiveMode_quick',\n",
    "                 '321': 'Morph_ThorHighImpactMode_quick',\n",
    "                 '322': 'Morph_Unsiege_quick',\n",
    "                 '326': 'Morph_VikingAssaultMode_quick',\n",
    "                 '327': 'Morph_VikingFighterMode_quick',\n",
    "                 '352': 'Research_AdvancedBallistics_quick',\n",
    "                 '353': 'Research_BansheeCloakingField_quick',\n",
    "                 '354': 'Research_BansheeHyperflightRotors_quick',\n",
    "                 '355': 'Research_BattlecruiserWeaponRefit_quick',\n",
    "                 '361': 'Research_CombatShield_quick',\n",
    "                 '362': 'Research_ConcussiveShells_quick',\n",
    "                 '363': 'Research_DrillingClaws_quick',\n",
    "                 '369': 'Research_HiSecAutoTracking_quick',\n",
    "                 '370': 'Research_HighCapacityFuelTanks_quick',\n",
    "                 '371': 'Research_InfernalPreigniter_quick',\n",
    "                 '375': 'Research_NeosteelFrame_quick',\n",
    "                 '378': 'Research_PersonalCloaking_quick',\n",
    "                 '39': 'Build_Armory_screen',\n",
    "                 '402': 'Research_RavenCorvidReactor_quick',\n",
    "                 '403': 'Research_RavenRecalibratedExplosives_quick',\n",
    "                 '405': 'Research_Stimpack_quick',\n",
    "                 '406': 'Research_TerranInfantryArmor_quick',\n",
    "                 '410': 'Research_TerranInfantryWeapons_quick',\n",
    "                 '414': 'Research_TerranShipWeapons_quick',\n",
    "                 '418': 'Research_TerranStructureArmorUpgrade_quick',\n",
    "                 '419': 'Research_TerranVehicleAndShipPlating_quick',\n",
    "                 '42': 'Build_Barracks_screen',\n",
    "                 '423': 'Research_TerranVehicleWeapons_quick',\n",
    "                 '43': 'Build_Bunker_screen',\n",
    "                 '44': 'Build_CommandCenter_screen',\n",
    "                 '453': 'Stop_quick',\n",
    "                 '459': 'Train_Banshee_quick',\n",
    "                 '460': 'Train_Battlecruiser_quick',\n",
    "                 '464': 'Train_Cyclone_quick',\n",
    "                 '468': 'Train_Ghost_quick',\n",
    "                 '469': 'Train_Hellbat_quick',\n",
    "                 '470': 'Train_Hellion_quick',\n",
    "                 '475': 'Train_Liberator_quick',\n",
    "                 '476': 'Train_Marauder_quick',\n",
    "                 '477': 'Train_Marine_quick',\n",
    "                 '478': 'Train_Medivac_quick',\n",
    "                 '487': 'Train_Raven_quick',\n",
    "                 '488': 'Train_Reaper_quick',\n",
    "                 '490': 'Train_SCV_quick',\n",
    "                 '492': 'Train_SiegeTank_quick',\n",
    "                 '496': 'Train_Thor_quick',\n",
    "                 '498': 'Train_VikingFighter_quick',\n",
    "                 '50': 'Build_EngineeringBay_screen',\n",
    "                 '502': 'Train_WidowMine_quick',\n",
    "                 '53': 'Build_Factory_screen',\n",
    "                 '56': 'Build_FusionCore_screen',\n",
    "                 '58': 'Build_GhostAcademy_screen',\n",
    "                 '64': 'Build_MissileTurret_screen',\n",
    "                 '66': 'Build_Nuke_quick',\n",
    "                 '71': 'Build_Reactor_quick',\n",
    "                 '72': 'Build_Reactor_screen',\n",
    "                 '79': 'Build_Refinery_screen',\n",
    "                 '83': 'Build_SensorTower_screen',\n",
    "                 '89': 'Build_Starport_screen',\n",
    "                 '91': 'Build_SupplyDepot_screen',\n",
    "                 '92': 'Build_TechLab_quick',\n",
    "                 '93': 'Build_TechLab_screen'}\n",
    "#sorted([int(val) for val in test['action_id'].values()])\n",
    "test = {}\n",
    "for key, value in action_id.items():\n",
    "    test[value] = key\n",
    "i=0\n",
    "for key, _ in actions.items():\n",
    "    print(action_name[str(test[str(key)])])\n",
    "    i+=1\n",
    "print(i) \n",
    "len(actions.keys())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "basicnn.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/neural_networks_tutorial.ipynb",
     "timestamp": 1573568002848
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
