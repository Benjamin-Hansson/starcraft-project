{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pklVAdTJ6J-B"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Nästa gång:\n",
    "# Välja ut passande input\n",
    "# Exportera model\n",
    "# importera model\n",
    "# träna på mer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_L-5xPvzna4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BatchEnv(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def init(self, path, root, race, enemy_race, step_mul=8, n_replays=4, n_steps=5, epochs=10, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        with open(path) as f:\n",
    "            replays = json.load(f)\n",
    "\n",
    "        self.replays = self.__generate_replay_list__(replays, root, race)\n",
    "\n",
    "        self.race = race\n",
    "        self.enemy_race = enemy_race\n",
    "\n",
    "        self.step_mul = step_mul\n",
    "        self.n_replays = n_replays\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.epoch = -1\n",
    "        self.steps = 0\n",
    "\n",
    "        self.replay_idx = -1\n",
    "        self.replay_list = [None for _ in range(self.n_replays)]\n",
    "        \n",
    "        \"\"\"\n",
    "        ## Display Progress Bar\n",
    "        self.epoch_pbar = tqdm(total=self.epochs, desc='Epoch')\n",
    "        self.replay_pbar = None\n",
    "        \"\"\"\n",
    "\n",
    "        self.__post_init__()\n",
    "\n",
    "    def __generate_replay_list__(self, replays, race):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __init_epoch__(self):\n",
    "        self.epoch += 1\n",
    "        \"\"\"\n",
    "        if self.epoch > 0:\n",
    "            self.epoch_pbar.update(1)\n",
    "        \"\"\"\n",
    "        if self.epoch == self.epochs:\n",
    "            return False\n",
    "\n",
    "        np.random.shuffle(self.replays)\n",
    "        \"\"\"\n",
    "        ## Display Progress Bar\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        self.replay_pbar = tqdm(total=len(self.replays), desc='  Replays')\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def __reset__(self):\n",
    "        self.replay_idx += 1\n",
    "        if self.replay_idx % len(self.replays) == 0:\n",
    "            has_more = self.__init_epoch__()\n",
    "            if not has_more:\n",
    "                return None\n",
    "\n",
    "        path = self.replays[self.replay_idx%len(self.replays)]\n",
    "\n",
    "        return self.__load_replay__(path)\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, **kwargs):\n",
    "        require_init = [False for _ in range(self.n_replays)]\n",
    "        for i in range(self.n_replays):\n",
    "            if self.replay_list[i] is None or self.replay_list[i]['done']:\n",
    "                if self.replay_list[i] is not None:\n",
    "                    keys = set(self.replay_list[i].keys())\n",
    "                    for k in keys:\n",
    "                        del self.replay_list[i][k]\n",
    "                self.replay_list[i] = self.__reset__()\n",
    "                require_init[i] = True\n",
    "            if self.replay_list[i] is None:\n",
    "                return None\n",
    "\n",
    "        result = []\n",
    "        for step in range(self.n_steps):\n",
    "            result_per_step = []\n",
    "            for i in range(self.n_replays):\n",
    "                replay_dict = self.replay_list[i]\n",
    "\n",
    "                features = self.__one_step__(replay_dict, replay_dict['done'])\n",
    "\n",
    "                result_per_step.append(features)\n",
    "\n",
    "            result.append(result_per_step)\n",
    "\n",
    "        return self.__post_process__(result, **kwargs), require_init\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __post_process__(self, result, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step_count(self):\n",
    "        return self.steps\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        if self.epoch_pbar is not None:\n",
    "            self.epoch_pbar.close()\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        \"\"\"\n",
    "class BatchGlobalFeatureEnv(BatchEnv):\n",
    "    n_features_dic = {'Terran':  {'Terran': 738,  'Protoss': 648,  'Zerg': 1116},\n",
    "                      'Protoss': {'Terran': 638,  'Protoss': 548,  'Zerg': 1016},\n",
    "                      'Zerg':    {'Terran': 1106, 'Protoss': 1016, 'Zerg': 1484}}\n",
    "    n_actions_dic = {'Terran': 75, 'Protoss': 61, 'Zerg': 74}\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.n_features = self.n_features_dic[self.race][self.enemy_race]\n",
    "        self.n_actions = self.n_actions_dic[self.race]\n",
    "\n",
    "    def __generate_replay_list__(self, replays, root, race):\n",
    "        result = []\n",
    "        for path_dict in replays:\n",
    "            for player_path in path_dict[race]:\n",
    "                result.append(os.path.join(root, player_path['global_path']))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        replay_dict = {}\n",
    "        replay_dict['ptr'] = 0\n",
    "        replay_dict['done'] = False\n",
    "        replay_dict['states'] = np.asarray(sparse.load_npz(path).todense())\n",
    "\n",
    "        return replay_dict\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        states = replay_dict['states']\n",
    "        feature_shape = states.shape[1:]\n",
    "        if done:\n",
    "            return np.zeros(feature_shape)\n",
    "\n",
    "        self.steps += 1\n",
    "        state = states[replay_dict['ptr']]\n",
    "        replay_dict['ptr'] += 1\n",
    "        if replay_dict['ptr'] == states.shape[0]:\n",
    "            #self.replay_pbar.update(1)\n",
    "            replay_dict['done'] = True\n",
    "\n",
    "        return state\n",
    "\n",
    "    def __post_process__(self, result, reward=True, action=False, score=False):\n",
    "        result = np.asarray(result)\n",
    "\n",
    "        result_return = [result[:, :, 15:]]\n",
    "        if reward:\n",
    "            result_return.append(result[:, :, 0:1])\n",
    "        if action:\n",
    "            result_return.append(result[:, :, 1:2])\n",
    "        if score:\n",
    "            result_return.append(result[:, :, 2:15])\n",
    "\n",
    "        return result_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5101,
     "status": "ok",
     "timestamp": 1573819158300,
     "user": {
      "displayName": "Dylan Mäenpää",
      "photoUrl": "https://lh5.googleusercontent.com/-G0n0W6eJ4i8/AAAAAAAAAAI/AAAAAAAAAC8/xxtHPKSBYvs/s64/photo.jpg",
      "userId": "01206227338381553752"
     },
     "user_tz": -60
    },
    "id": "KWg6kn_i6J-O",
    "outputId": "4f0eceda-7d3e-4049-b3b8-2532df0f3808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=78, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Input\n",
    "#\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2, 78)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5hLhTrLx9mf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7QZ9AYWvrvI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238\n",
      "torch.Size([1])\n",
      "<AddBackward0 object at 0x0000024040573588>\n",
      "Parameter containing:\n",
      "tensor([[0.5886],\n",
      "        [0.0722]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.6886],\n",
      "        [0.1722]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Require grad?!?\n",
    "# weight ?!?!?\n",
    "\n",
    "def train(model, env):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    env_return = env.step(reward=True, action=True)\n",
    "    \n",
    "    if env_return is not None:\n",
    "        (states, reward, actions_gt), require_init = env_return\n",
    "        \n",
    "    states = torch.from_numpy(states).float()\n",
    "    actions_gt = torch.from_numpy(actions_gt).long().view(1)\n",
    "    reward = torch.from_numpy(reward).float().view(-1, 1)\n",
    "    actions = model(reward)\n",
    "    \n",
    "    print(actions_gt.size())\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    loss += F.cross_entropy(actions, actions_gt)\n",
    "    print(loss.grad_fn)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    #print(model.fc1.weight)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    #print(model.fc1.weight)\n",
    "    \n",
    "model = Net()\n",
    "replay_path = ''\n",
    "dataset_path = ''\n",
    "race = 'Terran'\n",
    "enemy_race = 'Terran'\n",
    "#steps = 20 # ?\n",
    "n_replays = 1\n",
    "epochs = 1\n",
    "\n",
    "path = 'train_val_test/Terran_vs_Terran/train.json'\n",
    "phrase = 'train'\n",
    "\n",
    "env = BatchGlobalFeatureEnv()\n",
    "env.init(path, './', race, enemy_race, n_replays=1, n_steps=1)\n",
    "\n",
    "train(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raGDqFNX47Za"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "basicnn.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/neural_networks_tutorial.ipynb",
     "timestamp": 1573568002848
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
