{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pklVAdTJ6J-B"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_L-5xPvzna4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BatchEnv(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def init(self, path, root, race, enemy_race, step_mul=8, n_replays=4, n_steps=5, epochs=10, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        with open(path) as f:\n",
    "            replays = json.load(f)\n",
    "\n",
    "        self.replays = self.__generate_replay_list__(replays, root, race)\n",
    "\n",
    "        self.race = race\n",
    "        self.enemy_race = enemy_race\n",
    "\n",
    "        self.step_mul = step_mul\n",
    "        self.n_replays = n_replays\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.epoch = -1\n",
    "        self.steps = 0\n",
    "\n",
    "        self.replay_idx = -1\n",
    "        self.replay_list = [None for _ in range(self.n_replays)]\n",
    "        \n",
    "        ## Display Progress Bar\n",
    "        \"\"\"\n",
    "        self.epoch_pbar = tqdm(total=self.epochs, desc='Epoch')\n",
    "        self.replay_pbar = None\n",
    "        \"\"\"\n",
    "\n",
    "        self.__post_init__()\n",
    "\n",
    "    def __generate_replay_list__(self, replays, race):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __init_epoch__(self):\n",
    "        self.epoch += 1\n",
    "        \"\"\"\n",
    "        if self.epoch > 0:\n",
    "            self.epoch_pbar.update(1)\n",
    "        \"\"\"\n",
    "        if self.epoch == self.epochs:\n",
    "            return False\n",
    "\n",
    "        np.random.shuffle(self.replays)\n",
    "        ## Display Progress Bar\n",
    "        \"\"\"\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        self.replay_pbar = tqdm(total=len(self.replays), desc='  Replays')\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def __reset__(self):\n",
    "        self.replay_idx += 1\n",
    "        if self.replay_idx % len(self.replays) == 0:\n",
    "            has_more = self.__init_epoch__()\n",
    "            if not has_more:\n",
    "                return None\n",
    "\n",
    "        path = self.replays[self.replay_idx%len(self.replays)]\n",
    "\n",
    "        return self.__load_replay__(path)\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, **kwargs):\n",
    "        require_init = [False for _ in range(self.n_replays)]\n",
    "        for i in range(self.n_replays):\n",
    "            if self.replay_list[i] is None or self.replay_list[i]['done']:\n",
    "                if self.replay_list[i] is not None:\n",
    "                    keys = set(self.replay_list[i].keys())\n",
    "                    for k in keys:\n",
    "                        del self.replay_list[i][k]\n",
    "                self.replay_list[i] = self.__reset__()\n",
    "                require_init[i] = True\n",
    "            if self.replay_list[i] is None:\n",
    "                return None\n",
    "\n",
    "        result = []\n",
    "        for step in range(self.n_steps):\n",
    "            result_per_step = []\n",
    "            for i in range(self.n_replays):\n",
    "                replay_dict = self.replay_list[i]\n",
    "\n",
    "                features = self.__one_step__(replay_dict, replay_dict['done'])\n",
    "\n",
    "                result_per_step.append(features)\n",
    "\n",
    "            result.append(result_per_step)\n",
    "\n",
    "        return self.__post_process__(result, **kwargs), require_init\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __post_process__(self, result, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step_count(self):\n",
    "        return self.steps\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        if self.epoch_pbar is not None:\n",
    "            self.epoch_pbar.close()\n",
    "        if self.replay_pbar is not None:\n",
    "            self.replay_pbar.close()\n",
    "        \"\"\"\n",
    "            \n",
    "class BatchGlobalFeatureEnv(BatchEnv):\n",
    "    n_features_dic = {'Terran':  {'Terran': 738,  'Protoss': 648,  'Zerg': 1116},\n",
    "                      'Protoss': {'Terran': 638,  'Protoss': 548,  'Zerg': 1016},\n",
    "                      'Zerg':    {'Terran': 1106, 'Protoss': 1016, 'Zerg': 1484}}\n",
    "    n_actions_dic = {'Terran': 75, 'Protoss': 61, 'Zerg': 74}\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.n_features = self.n_features_dic[self.race][self.enemy_race]\n",
    "        self.n_actions = self.n_actions_dic[self.race]\n",
    "\n",
    "    def __generate_replay_list__(self, replays, root, race):\n",
    "        result = []\n",
    "        for path_dict in replays:\n",
    "            for player_path in path_dict[race]:\n",
    "                result.append(os.path.join(root, player_path['global_path']))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __load_replay__(self, path):\n",
    "        replay_dict = {}\n",
    "        replay_dict['ptr'] = 0\n",
    "        replay_dict['done'] = False\n",
    "        replay_dict['states'] = np.asarray(sparse.load_npz(path).todense())\n",
    "\n",
    "        return replay_dict\n",
    "\n",
    "    def __one_step__(self, replay_dict, done):\n",
    "        states = replay_dict['states']\n",
    "        feature_shape = states.shape[1:]\n",
    "        if done:\n",
    "            return np.zeros(feature_shape)\n",
    "\n",
    "        self.steps += 1\n",
    "        state = states[replay_dict['ptr']]\n",
    "        replay_dict['ptr'] += 1\n",
    "        if replay_dict['ptr'] == states.shape[0]:\n",
    "            #self.replay_pbar.update(1)\n",
    "            replay_dict['done'] = True\n",
    "    \n",
    "        return state\n",
    "\n",
    "    def __post_process__(self, result, reward=True, action=False, score=False):\n",
    "        result = np.asarray(result)\n",
    "\n",
    "        result_return = [result[:, :, 15:]]\n",
    "        if reward:\n",
    "            result_return.append(result[:, :, 0:1])\n",
    "        if action:\n",
    "            result_return.append(result[:, :, 1:2])\n",
    "        if score:\n",
    "            result_return.append(result[:, :, 2:15])\n",
    "\n",
    "        return result_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5101,
     "status": "ok",
     "timestamp": 1573819158300,
     "user": {
      "displayName": "Dylan Mäenpää",
      "photoUrl": "https://lh5.googleusercontent.com/-G0n0W6eJ4i8/AAAAAAAAAAI/AAAAAAAAAC8/xxtHPKSBYvs/s64/photo.jpg",
      "userId": "01206227338381553752"
     },
     "user_tz": -60
    },
    "id": "KWg6kn_i6J-O",
    "outputId": "4f0eceda-7d3e-4049-b3b8-2532df0f3808"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 75)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all features except for\n",
    "# minerals, vespene, food_cap, food_used, food_army, food_workers\n",
    "def transform(states):\n",
    "    mask = np.ones([1, 256, 738], dtype=bool)\n",
    "    mask[:, :, 7:] = False\n",
    "    mask[:, :, 0] = False\n",
    "    states=states[mask]\n",
    "    return states\n",
    "\n",
    "# Removes doing nothing action\n",
    "def transform2(states, actions, n_replays):\n",
    "    mask = np.ones(n_replays, dtype=bool)\n",
    "    for i, action in enumerate(actions.squeeze()):\n",
    "        if action == 74:\n",
    "            mask[i] = False\n",
    "    actions = actions.squeeze()[mask]\n",
    "    states = transform(states)\n",
    "    states = np.reshape(states, (256, -1))\n",
    "    states = states[mask]\n",
    "    return states, actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7QZ9AYWvrvI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import visdom\n",
    "import sys\n",
    "\n",
    "# Require grad?!?\n",
    "# weight ?!?!?\n",
    "# Todo:\n",
    "# 1. skapa baseline\n",
    "# 2. jämföra en epok och see accuracy\n",
    "# 3. top 3 error rate test?!\n",
    "# 4. see om predictions ser rimliga ut för många fall\n",
    "\n",
    "\n",
    "def train(model, env):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    env_return = env.step(reward=True, action=True)\n",
    "    print(env.epochs)\n",
    "    \n",
    "    if env_return is not None:\n",
    "        (states, reward, actions_gt), require_init = env_return\n",
    "   \n",
    "    # Remove doing nothing\n",
    "    states = torch.from_numpy(states).float().view(env.n_replays, -1)\n",
    "    actions_gt = torch.from_numpy(actions_gt).long().squeeze()\n",
    "    \n",
    "    states, actions_gt = transform2(states, actions_gt, n_replays)\n",
    "    running_loss = 0\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        #print(\"steps: {} \\n epochs: {} \", end='\\r')#.format(env.steps, env.epochs))\n",
    "        print(\"steps: {}, replay: {}/{} epoch: {}\".format(env.step_count(), env.replay_idx, len(env.replays), env.epoch+1), end=\"\\r\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # since we are not using steps we need o reshape result\n",
    "        actions = model(states)\n",
    "        \n",
    "        loss = 0\n",
    "        loss += F.cross_entropy(actions, actions_gt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #print(model.fc1.weight)\n",
    "        optimizer.step()\n",
    "        #print(model.fc1.weight)\n",
    "        \n",
    "        \n",
    "        env_return = env.step(reward=False, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_states, raw_actions_gt), require_init = env_return\n",
    "            states = torch.from_numpy(raw_states).float().view(env.n_replays, -1)\n",
    "            actions_gt = torch.from_numpy(raw_actions_gt).long().squeeze()\n",
    "            states, actions_gt = transform2(states, actions_gt, n_replays)\n",
    "        \n",
    "        #env.step_count() > save or\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if env.steps % 2000 == 0:\n",
    "            print(\"loss: {}\".format(running_loss/2000))\n",
    "            running_loss = 0\n",
    "        if env.epoch == env.epochs:\n",
    "            torch.save(model.state_dict(), 'model_iter_{}.pth'.format(env.step_count()))\n",
    "            return\n",
    "        if env_return is None:\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "replay_path = ''\n",
    "dataset_path = ''\n",
    "race = 'Terran'\n",
    "enemy_race = 'Terran'\n",
    "steps = 20 # ?\n",
    "n_replays = 256\n",
    "epochs = 1\n",
    "model = Net()\n",
    "\n",
    "path = 'train_val_test/Terran_vs_Terran/train.json'\n",
    "phrase = 'train'\n",
    "\n",
    "env = BatchGlobalFeatureEnv()\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=3)\n",
    "\n",
    "train(model, env)\n",
    "path = \"train_val_test/Terran_vs_Terran/val.json\"\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=1)\n",
    "accuracy, actions = test(model, env)\n",
    "print()\n",
    "print(accuracy)\n",
    "\n",
    "#initial features\n",
    "\"\"\"\n",
    "tensor([0.0001, 0.0008, 0.0000, 0.0750, 0.0600, 0.0000, 0.0600, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raGDqFNX47Za"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test(model, env):\n",
    "    print(\"Testing\")\n",
    "    ######################### SAVE RESULT ############################\n",
    "    total_data_points = 0\n",
    "    correct = 0\n",
    "    correct_dumb = 0\n",
    "    correct_three = 0\n",
    "    saved_actions = defaultdict(int)\n",
    "    ######################### TEST ###################################\n",
    "    env_return = env.step(reward=False, action=True)\n",
    "    if env_return is not  None:\n",
    "        (states, actions_gt), require_init = env_return\n",
    "        states = transform(states)\n",
    "        states = torch.from_numpy(states).float().view(env.n_replays, -1)\n",
    "        actions_gt = torch.from_numpy(actions_gt).long().squeeze()\n",
    "    not_bad = 0\n",
    "    while True:\n",
    "        print(\"steps: {}, replay: {}/{} epoch: {}\".format(env.step_count(), env.replay_idx, len(env.replays), env.epoch+1), end=\"\\r\")\n",
    "        actions = model(states).view(env.n_replays, -1)\n",
    "        actions.detach()\n",
    "        #rint(np.argpartition(actions[0].detach().numpy(), -3)[-3:])\n",
    "        #beak\n",
    "        ########################### NEXT BATCH #############################################\n",
    "        actions_np = np.squeeze(np.vstack([np.argpartition(action.detach().numpy(), -3)[-3:] for action in actions]))\n",
    "        #actions_np = np.squeeze(np.vstack([np.argmax(action.data.cpu().numpy(), axis=0) for action in actions]))\n",
    "        for three_actions in actions_np:\n",
    "            for action in three_actions:\n",
    "                saved_actions[action] +=1\n",
    "        actions_gt_np = np.squeeze(actions_gt.cpu().numpy())\n",
    "        for i, action in enumerate(actions_gt_np):\n",
    "            if action != 74:\n",
    "                if action == actions_np[i][2]:\n",
    "                    correct += 1\n",
    "                if action in actions_np[i]:\n",
    "                    correct_three += 1\n",
    "                if action == 62:\n",
    "                    correct_dumb += 1\n",
    "                total_data_points += 1\n",
    "                \n",
    "        if env.epoch == env.epochs:\n",
    "            break\n",
    "        \n",
    "        env_return = env.step(reward=False, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_states, raw_actions), require_init = env_return\n",
    "            raw_states = transform(raw_states)\n",
    "            states = states.copy_(torch.from_numpy(raw_states).float().view(env.n_replays, -1))\n",
    "            actions_gt = actions_gt.copy_(torch.from_numpy(raw_actions).long().squeeze())\n",
    "        else:\n",
    "            env.close()\n",
    "    \n",
    "\n",
    "    return correct / total_data_points, correct_dumb/total_data_points, correct_three/total_data_points, saved_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "steps: 469248, replay: 980/980 epoch: 2\r"
     ]
    }
   ],
   "source": [
    "replay_path = ''\n",
    "dataset_path = ''\n",
    "race = 'Terran'\n",
    "enemy_race = 'Terran'\n",
    "steps = 20 # ?\n",
    "n_replays = 256\n",
    "epochs = 1\n",
    "model = Net()\n",
    "\n",
    "path = 'train_val_test/Terran_vs_Terran/train.json'\n",
    "phrase = 'train'\n",
    "\n",
    "model = Net()\n",
    "path = \"train_val_test/Terran_vs_Terran/val.json\"\n",
    "PATH = \"model_iter_11638016.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "env = BatchGlobalFeatureEnv()\n",
    "env.init(path, './', race, enemy_race, n_replays=n_replays, n_steps=1, epochs=1)\n",
    "accuracy, accuracy_dumb, accuracy_three, actions = test(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {34: 8425,\n",
       "             11: 34696,\n",
       "             62: 450008,\n",
       "             41: 31576,\n",
       "             48: 175707,\n",
       "             15: 27104,\n",
       "             27: 16969,\n",
       "             13: 20598,\n",
       "             51: 414421,\n",
       "             22: 15799,\n",
       "             60: 8340,\n",
       "             21: 7394,\n",
       "             36: 81,\n",
       "             47: 8725,\n",
       "             50: 5301,\n",
       "             42: 1395,\n",
       "             29: 23298,\n",
       "             26: 89631,\n",
       "             64: 42001,\n",
       "             46: 600,\n",
       "             52: 526,\n",
       "             68: 25311,\n",
       "             31: 551,\n",
       "             19: 50,\n",
       "             28: 2,\n",
       "             71: 2,\n",
       "             35: 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop_quick\n",
      "Cancel_Last_quick\n",
      "Train_SCV_quick\n",
      "Build_Refinery_screen\n",
      "Build_SupplyDepot_screen\n",
      "Build_CommandCenter_screen\n",
      "Morph_SupplyDepot_Lower_quick\n",
      "Build_Barracks_screen\n",
      "Train_Marine_quick\n",
      "Morph_OrbitalCommand_quick\n",
      "Train_Reaper_quick\n",
      "Build_Factory_screen\n",
      "Build_Reactor_quick\n",
      "Build_Starport_screen\n",
      "Build_TechLab_quick\n",
      "Train_Cyclone_quick\n",
      "Build_MissileTurret_screen\n",
      "Morph_SiegeMode_quick\n",
      "Train_SiegeTank_quick\n",
      "Train_Hellion_quick\n",
      "Train_Medivac_quick\n",
      "Train_VikingFighter_quick\n",
      "Morph_Unsiege_quick\n",
      "Morph_LiberatorAGMode_screen\n",
      "Morph_SupplyDepot_Raise_quick\n",
      "Train_WidowMine_quick\n",
      "Morph_VikingAssaultMode_quick\n",
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_id =  {'140': '1',\n",
    "               '168': '11',\n",
    "               '261': '0',\n",
    "               '300': '16',\n",
    "               '301': '17',\n",
    "               '304': '18',\n",
    "               '305': '19',\n",
    "               '309': '22',\n",
    "               '312': '23',\n",
    "               '317': '26',\n",
    "               '318': '27',\n",
    "               '319': '28',\n",
    "               '320': '33',\n",
    "               '321': '30',\n",
    "               '322': '31',\n",
    "               '326': '35',\n",
    "               '327': '38',\n",
    "               '352': '58',\n",
    "               '353': '55',\n",
    "               '354': '57',\n",
    "               '355': '56',\n",
    "               '361': '61',\n",
    "               '362': '63',\n",
    "               '363': '65',\n",
    "               '369': '67',\n",
    "               '370': '70',\n",
    "               '371': '69',\n",
    "               '375': '72',\n",
    "               '378': '73',\n",
    "               '39': '10',\n",
    "               '402': '2',\n",
    "               '403': '3',\n",
    "               '405': '4',\n",
    "               '406': '5',\n",
    "               '410': '6',\n",
    "               '414': '7',\n",
    "               '418': '8',\n",
    "               '419': '9',\n",
    "               '42': '13',\n",
    "               '423': '12',\n",
    "               '43': '14',\n",
    "               '44': '15',\n",
    "               '453': '34',\n",
    "               '459': '39',\n",
    "               '460': '40',\n",
    "               '464': '42',\n",
    "               '468': '44',\n",
    "               '469': '45',\n",
    "               '470': '46',\n",
    "               '475': '54',\n",
    "               '476': '49',\n",
    "               '477': '51',\n",
    "               '478': '52',\n",
    "               '487': '59',\n",
    "               '488': '60',\n",
    "               '490': '62',\n",
    "               '492': '64',\n",
    "               '496': '66',\n",
    "               '498': '68',\n",
    "               '50': '20',\n",
    "               '502': '71',\n",
    "               '53': '21',\n",
    "               '56': '24',\n",
    "               '58': '25',\n",
    "               '64': '29',\n",
    "               '66': '32',\n",
    "               '71': '36',\n",
    "               '72': '37',\n",
    "               '79': '41',\n",
    "               '83': '43',\n",
    "               '89': '47',\n",
    "               '91': '48',\n",
    "               '92': '50',\n",
    "               '93': '53'}\n",
    "action_name = { '140': 'Cancel_quick',\n",
    "                 '168': 'Cancel_Last_quick',\n",
    "                 '261': 'Halt_quick',\n",
    "                 '300': 'Morph_Hellbat_quick',\n",
    "                 '301': 'Morph_Hellion_quick',\n",
    "                 '304': 'Morph_LiberatorAAMode_quick',\n",
    "                 '305': 'Morph_LiberatorAGMode_screen',\n",
    "                 '309': 'Morph_OrbitalCommand_quick',\n",
    "                 '312': 'Morph_PlanetaryFortress_quick',\n",
    "                 '317': 'Morph_SiegeMode_quick',\n",
    "                 '318': 'Morph_SupplyDepot_Lower_quick',\n",
    "                 '319': 'Morph_SupplyDepot_Raise_quick',\n",
    "                 '320': 'Morph_ThorExplosiveMode_quick',\n",
    "                 '321': 'Morph_ThorHighImpactMode_quick',\n",
    "                 '322': 'Morph_Unsiege_quick',\n",
    "                 '326': 'Morph_VikingAssaultMode_quick',\n",
    "                 '327': 'Morph_VikingFighterMode_quick',\n",
    "                 '352': 'Research_AdvancedBallistics_quick',\n",
    "                 '353': 'Research_BansheeCloakingField_quick',\n",
    "                 '354': 'Research_BansheeHyperflightRotors_quick',\n",
    "                 '355': 'Research_BattlecruiserWeaponRefit_quick',\n",
    "                 '361': 'Research_CombatShield_quick',\n",
    "                 '362': 'Research_ConcussiveShells_quick',\n",
    "                 '363': 'Research_DrillingClaws_quick',\n",
    "                 '369': 'Research_HiSecAutoTracking_quick',\n",
    "                 '370': 'Research_HighCapacityFuelTanks_quick',\n",
    "                 '371': 'Research_InfernalPreigniter_quick',\n",
    "                 '375': 'Research_NeosteelFrame_quick',\n",
    "                 '378': 'Research_PersonalCloaking_quick',\n",
    "                 '39': 'Build_Armory_screen',\n",
    "                 '402': 'Research_RavenCorvidReactor_quick',\n",
    "                 '403': 'Research_RavenRecalibratedExplosives_quick',\n",
    "                 '405': 'Research_Stimpack_quick',\n",
    "                 '406': 'Research_TerranInfantryArmor_quick',\n",
    "                 '410': 'Research_TerranInfantryWeapons_quick',\n",
    "                 '414': 'Research_TerranShipWeapons_quick',\n",
    "                 '418': 'Research_TerranStructureArmorUpgrade_quick',\n",
    "                 '419': 'Research_TerranVehicleAndShipPlating_quick',\n",
    "                 '42': 'Build_Barracks_screen',\n",
    "                 '423': 'Research_TerranVehicleWeapons_quick',\n",
    "                 '43': 'Build_Bunker_screen',\n",
    "                 '44': 'Build_CommandCenter_screen',\n",
    "                 '453': 'Stop_quick',\n",
    "                 '459': 'Train_Banshee_quick',\n",
    "                 '460': 'Train_Battlecruiser_quick',\n",
    "                 '464': 'Train_Cyclone_quick',\n",
    "                 '468': 'Train_Ghost_quick',\n",
    "                 '469': 'Train_Hellbat_quick',\n",
    "                 '470': 'Train_Hellion_quick',\n",
    "                 '475': 'Train_Liberator_quick',\n",
    "                 '476': 'Train_Marauder_quick',\n",
    "                 '477': 'Train_Marine_quick',\n",
    "                 '478': 'Train_Medivac_quick',\n",
    "                 '487': 'Train_Raven_quick',\n",
    "                 '488': 'Train_Reaper_quick',\n",
    "                 '490': 'Train_SCV_quick',\n",
    "                 '492': 'Train_SiegeTank_quick',\n",
    "                 '496': 'Train_Thor_quick',\n",
    "                 '498': 'Train_VikingFighter_quick',\n",
    "                 '50': 'Build_EngineeringBay_screen',\n",
    "                 '502': 'Train_WidowMine_quick',\n",
    "                 '53': 'Build_Factory_screen',\n",
    "                 '56': 'Build_FusionCore_screen',\n",
    "                 '58': 'Build_GhostAcademy_screen',\n",
    "                 '64': 'Build_MissileTurret_screen',\n",
    "                 '66': 'Build_Nuke_quick',\n",
    "                 '71': 'Build_Reactor_quick',\n",
    "                 '72': 'Build_Reactor_screen',\n",
    "                 '79': 'Build_Refinery_screen',\n",
    "                 '83': 'Build_SensorTower_screen',\n",
    "                 '89': 'Build_Starport_screen',\n",
    "                 '91': 'Build_SupplyDepot_screen',\n",
    "                 '92': 'Build_TechLab_quick',\n",
    "                 '93': 'Build_TechLab_screen'}\n",
    "#sorted([int(val) for val in test['action_id'].values()])\n",
    "test = {}\n",
    "for key, value in action_id.items():\n",
    "    test[value] = key\n",
    "i=0\n",
    "for key, _ in actions.items():\n",
    "    print(action_name[str(test[str(key)])])\n",
    "    i+=1\n",
    "print(i) \n",
    "len(actions.keys())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "basicnn.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/neural_networks_tutorial.ipynb",
     "timestamp": 1573568002848
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
